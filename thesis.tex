% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  english,
  man,floatsintext]{apa6}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Explaining contingency judgements with a computational model of instance-based memory},
  pdfauthor={Austin Kaplan1},
  pdflang={en-EN},
  pdfkeywords={memory, contingency judgments, MINERVA II, instance theory},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
% Manuscript styling
\usepackage{upgreek}
\captionsetup{font=singlespacing,justification=justified}

% Table formatting
\usepackage{longtable}
\usepackage{lscape}
% \usepackage[counterclockwise]{rotating}   % Landscape page setup for large tables
\usepackage{multirow}		% Table styling
\usepackage{tabularx}		% Control Column width
\usepackage[flushleft]{threeparttable}	% Allows for three part tables with a specified notes section
\usepackage{threeparttablex}            % Lets threeparttable work with longtable

% Create new environments so endfloat can handle them
% \newenvironment{ltable}
%   {\begin{landscape}\begin{center}\begin{threeparttable}}
%   {\end{threeparttable}\end{center}\end{landscape}}
\newenvironment{lltable}{\begin{landscape}\begin{center}\begin{ThreePartTable}}{\end{ThreePartTable}\end{center}\end{landscape}}

% Enables adjusting longtable caption width to table width
% Solution found at http://golatex.de/longtable-mit-caption-so-breit-wie-die-tabelle-t15767.html
\makeatletter
\newcommand\LastLTentrywidth{1em}
\newlength\longtablewidth
\setlength{\longtablewidth}{1in}
\newcommand{\getlongtablewidth}{\begingroup \ifcsname LT@\roman{LT@tables}\endcsname \global\longtablewidth=0pt \renewcommand{\LT@entry}[2]{\global\advance\longtablewidth by ##2\relax\gdef\LastLTentrywidth{##2}}\@nameuse{LT@\roman{LT@tables}} \fi \endgroup}

% \setlength{\parindent}{0.5in}
% \setlength{\parskip}{0pt plus 0pt minus 0pt}

% \usepackage{etoolbox}
\makeatletter
\patchcmd{\HyOrg@maketitle}
  {\section{\normalfont\normalsize\abstractname}}
  {\section*{\normalfont\normalsize\abstractname}}
  {}{\typeout{Failed to patch abstract.}}
\patchcmd{\HyOrg@maketitle}
  {\section{\protect\normalfont{\@title}}}
  {\section*{\protect\normalfont{\@title}}}
  {}{\typeout{Failed to patch title.}}
\makeatother
\shorttitle{Memory and contingency judgements}
\keywords{memory, contingency judgments, MINERVA II, instance theory\newline\indent Word count: 2180}
\usepackage{lineno}

\linenumbers
\usepackage{csquotes}
\ifxetex
  % Load polyglossia as late as possible: uses bidi with RTL langages (e.g. Hebrew, Arabic)
  \usepackage{polyglossia}
  \setmainlanguage[]{english}
\else
  \usepackage[shorthands=off,main=english]{babel}
\fi

\title{Explaining contingency judgements with a computational model of instance-based memory}
\author{Austin Kaplan\textsuperscript{1}}
\date{}


\authornote{

Brooklyn College of Psychology, submitted for PSYC 5001 (Dr.~Matthew Crump) as part of a two-semester honors thesis. This paper will be integrated into the final honors thesis to be submitted for PSYC 5002.

Correspondence concerning this article should be addressed to Austin Kaplan, 2900 Bedford Avenue. E-mail: \href{mailto:aus10kap@aol.com}{\nolinkurl{aus10kap@aol.com}}

}

\affiliation{\vspace{0.5cm}\textsuperscript{1} Brooklyn College}

\abstract{
The purpose of this experiment is to create a simulated version of a study done by Crump, Hannah, Allan, and Hord (2007). Our model replicated several key findings, such as the \(\triangle\)P and outcome density effects. We created a model using RStudio, based on MINERVA 2, which is a simulation model of episodic memory (Hintzman, 1986). MINERVA 2 assumes that each experience leaves an individual memory trace. Our model was presented with four different conditions. Two were high outcome density and two were low outcome density conditions. Low outcome density refers to a trial in which fewer outcomes were presented that cues. High outcome density refers to trials where more outcomes were presented than cues. Four types of trials can be presented to the model. The model can be presented with a cue and no outcome, no cue and no outcome, a cue and an outcome, or no cue and no outcome. Our model was shown all four combinations. It was then asked to predict whether an outcome would occur given that cues were presented first with no outcomes. We hypothesized that just like the human participants in the original study, our computer model also had high contingency ratings when more outcomes were presented than cues (high outcome density). In contingent conditions (\(\triangle\)P=.467), contingency ratings were much higher overall than noncontingent conditions (\(\triangle\)P = 0), which, as intended, paralleled the original results. However, it did so with regard to a higher expectation than that of the original study.
}



\begin{document}
\maketitle

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Imagine driving down a highway at a speed of sixty miles per hour. Suddenly, you hear on the radio that a car accident has occurred on the same highway that you are driving on. Subsequently, you anticipate a longer commute time. Why did you predict a longer commute? These types of questions are asked by researchers when studying contingency judgements. A contingency judgement can be defined as one's perception of whether a particular stimulus predicts a particular outcome. The purpose of studying human contingency judgements is to gain a better understanding of the way that people learn about the causal relationships between events (Beckers, De Houwer, \& Matute, 2007).
In order to study this further, we created a model using RStudio. The model is based on MINERVA 2, which is a simulation model of episodic memory. Specifically. MINERVA 2 assumes that each experience leaves an individual memory trace Hintzman (1986). First, the model is presented with an initial amount of cues and outcomes. Next, its memory is subsequently tested by asking the model to predict whether an outcome will occur given that a cue was presented or not. Our model focuses on evaluating the percentage of information remembered.

In order to give an idea of what our model explains, I will first review the current literature on human contingency judgements. Next, I will describe current theories of contingency learning and explain how they differ from my proposal. Finally, I will discuss how MINERVA 2 approaches these theories.

\hypertarget{the-contingency-judgment-literature-tasks-and-phenomena}{%
\subsection{The contingency judgment literature: tasks and phenomena}\label{the-contingency-judgment-literature-tasks-and-phenomena}}

Our experiment is based on a research study performed by Crump, Hannah, Allan, and Hord (2007). While this study involved presenting humans with a contingency task, our computer model attempts to replicate the findings of this study, and expand upon it. The findings of the original study explain that people are generally normative. In other words, people generally act in an expected way when making contingency judgements. For instance, if someone changes the brightness of their phone screen and it becomes brighter, a person will be able to tell that an increase occurred rather than a decrease, or no change. This would be expected, or normative, behavior. The \(\triangle\)P rule is rooted in this idea (Allan, 1993). In Crump et al. (2007), when a red circle is presented after a blue square, participants learn to associate the circle with the square and form a judgement that the circle is contingent upon the prior presentation of the square. Specifically, if more outcomes are presented participants are led to make a greater judgement of contingency. This is because human beings are not robots, and each person has their own biases. These biases are explained by the outcome density effect, which states that when more outcomes occur, participants are more likely to predict that a contingency is present despite the contrary being true. In the Crump et al. (2007) study, in the high outcome density noncontingent condition (participants were shown \enquote{a cue and an outcome} the same amount of times as \enquote{no cue and an outcome}) participant predicted a contingency, as they saw a cue paired with an outcome many times over. In reality, a cue was also paired with no outcome just as many times, and so no contingency was present. Nothing about the cue predicted the occurrence of an outcome.

\hypertarget{what-is-a-contingency}{%
\subsubsection{What is a contingency?}\label{what-is-a-contingency}}

Contingency is defined as a statistical relationship between two variables. Described in detail by Crump et al. (2007), \enquote{A cue is either presented (C) or not presented (\textasciitilde C)}, and an outcome either occurs (O) or does not occur (\textasciitilde O). As a result, there are four possible cue-outcome pairings that can be presented with varying frequencies to manipulate the cue-outcome relationship. Table 1 displays a 2x2 contingency table representing the four different cue-outcome pairings. The letters inside each cell (A, B, C, D) denote the frequency of occurrence of each cue-outcome pair presented over trials. Conventionally, the contingency between the cue-outcome pairs over trials is defined by the \(\triangle\)P rule (see Allan, 1980)''. \(\triangle\)P is defined as the contingency between the cue-outcome pairs over trials. How do we compute \(\triangle\)P? The formula to compute \(\triangle\)P is {[}insert formula{]}. The table described by Crump et al. (2007) contains four possibilities. First, a cue is presented and an outcome occurs (A). Second, a cue is presented and an outcome does not occur (B). Third, a cue is not presented and an outcome occurs (C). Fourth, a cue is not presented and an outcome does not occur (D). \(\triangle\)P can range from 1 to -1. When \(\triangle\)P is 1, the presence of a cue predicts the occurrence of an outcome. When \(\triangle\)P is -1, the presence of a cue predicts the absence of an outcome.

\hypertarget{assessing-contingency-judgment-ability}{%
\subsubsection{Assessing contingency judgment ability}\label{assessing-contingency-judgment-ability}}

According to Crump et al. (2007), \enquote{Contingency tasks typically involve participants rating the strength of relationship between binary variables that have been paired over several trials}. People are presented with pairs (ABCD frequency information) of cue-outcome events, and then asked to make judgements of contingency between the cue and the outcome. There are several possible tasks given to participants to test for this ability. For example, Crump et al. (2007) used the streamed trials procedure. This showed cues and outcomes with each event separated by a black screen, in 100ms intervals. The screen would show either a cue (blue square) or an outcome (red circle) by itself, or a cue paired with an outcome. (During each block of 20 streamed trials each, participants were asked at random to complete a total of 10 contingency rating judgements as well as 10 frequency estimate judgements. The contingency rating judgements were collected using a sliding scale, where participants could choose between -100 and +100. In order to take in frequency estimate judgements, participants were presented with four images, each representing one of the four cue-outcome events. One field was left empty, in which participants were told to write in an estimate of the frequency of occurrence for each circumstance. The Crump et al., 2007 study tested for the contingency effect as well as the outcome density effect by manipulating the number of cues and outcomes presented in each condition.)

\hypertarget{classical-contingency-judgment-phenomena}{%
\subsubsection{Classical contingency judgment phenomena}\label{classical-contingency-judgment-phenomena}}

The contingency effect explains that humans are capable of making contingency judgements. The discrete-trial procedure is a common method used to test this effect. Allan (1993) describes several studies that use this. She first describes the Allan and Jenkins (1980) study which involved presenting subjects with an empty lake scene in which they could respond by either moving or not moving a joystick. After performing this action, the scene would either change to a picture of the lake with the Loch Ness Monster in it, or it would remain the same. Allan also describes a study by Shanks et al., in which participants were shown a tank moving across the screen and passing a gun sight. Participants chose either to fire or not fire at the tank, and then observed whether or not the tank was destroyed. In each of these examples, participants were able to tell whether their actions produced an outcome, and this is the contingency effect. In Crump et al. (2007), participants were shown 20 streamed trials, each presenting 60 cue-outcome pairs. 10 trials randomly asked for a contingency rating, while the other 10 asked for a frequency estimate. Participants were more likely to report a contingency when more contingencies were presented (either cue-outcome, or no cue and no outcome). This again illustrates the contingency effect.

\begin{figure}
\centering
\includegraphics{imgs/crump_figure2.png}
\caption{\label{fig:unnamed-chunk-1}Original matrices from Crump et al. (2007)}
\end{figure}

\hypertarget{theoretical-process-accounts-of-contingency-judgments}{%
\subsection{Theoretical process accounts of Contingency judgments}\label{theoretical-process-accounts-of-contingency-judgments}}

In studies seeking to determine whether humans make accurate judgements of contingency between two variables, most report a high correlation between contingency judgements and the actual contingency between input and output variables. What psychological mechanisms are involved in making contingency judgements? Several theories can be used to explain the way in which contingency judgements work. Some are non-instance theories, which assume that memories are lost, and that people do not remember specific instances of memory. Instead, they assume that people use a mathematical relationship or a generalization in order to recall information. Other theories do assume that people remember specific instances, and pool them together.

\hypertarget{rule-based-accounts}{%
\subsubsection{Rule-based accounts}\label{rule-based-accounts}}

One of these is called a rule-based account. Rule-based theories look at people as intuitive statisticians who extract contingency information by applying formulas (Allan, 1993). For example, Allan discusses the \(\triangle\)P rule, which is defined as the difference between two independent conditional probabilities. In other words, people act as \enquote{calculators}, and use the \(\triangle\)P formula unwittingly in order to report a contingency value. This is a non-instance account, as it is an abstractive process by which people convert memories to numbers, and then apply the formula. Ordering a package from Amazon is a real-world example we can use to illustrate this idea. The company usually posts a photo online of one's doorstep to show that their order was delivered, however, this is not always the case. Four possible outcomes can occur. First, an order is delivered and a picture is posted (A). Second, an order is delivered and a picture is not posted. Third, an order is not delivered and a picture is posted. Fourth, an order is not delivered and a picture is not posted. If one was asked to determine the percentage of times scenario (A) has occurred compared to the percentage of time scenario (D) has occurred, they will likely be able to give a rough estimate. According to rule-based theory, they do this by using the \(\triangle\)P formula unwittingly. Rule-based theories explain the outcome density effect by acknowledging human error occurs when making calculations.

\hypertarget{associative-accounts}{%
\subsubsection{Associative accounts}\label{associative-accounts}}

Associative theory explains that contingency judgements are formed through conditioning. This is rooted in the Rescorla-Wagner model of learning, which explains that learning diminishes as a conditioned stimulus becomes more familiar. According to this line of reasoning, contingencies are learned through the repeated presentation of stimuli. The Rescorla-Wagner model explains that when a CS is frequently paired with a US and is consistent in eliciting a CR, the CS has associative strength. Under these circumstances, participants will easily come to associate the CS with the US, and respond accordingly. The model infers that once conditioned, people do not think of the US itself and instead recall past encounters with the US in order to respond to it. Specifically, Rescorla and Wagner state, \enquote{changes in the strength of a stimulus depend upon the total associative strength of the compound in which that stimulus appears}. This is similar to the speaker normalization theory. This assumes that when a word is heard, people respond to memories of hearing that word, rather than the particular voice of the speaker in the current instance. Remarking on this theory, Goldringer states, \enquote{many perceptual and memorial data are best understood in terms of episodic representations}. Rescorla and Wagner support their assertion that all stimuli present when the US occurs are important to consider. They do this by discussing the blocking effect, which occurs when a new association is unable to be properly formed due to a previous association with the US. This gives credence to the idea that memory may play a role when hearing words, as most words have been heard previously, and therefore may have specific connotations due to past experiences. Associative theories explain the outcome density effect through the detail lost when generalizations are formed in memory.

\hypertarget{signal-detection-accounts}{%
\subsubsection{Signal-detection accounts}\label{signal-detection-accounts}}

Signal detection theory deals with measuring one's ability to differentiate between actual information and random patterns that distract from it. Based on this theory, contingency judgements are formed based on one's ability to separate noise (random pairings) from actual contingencies. Several factors may influence one's judgement. A minimum amount of change is necessary for one to be able to notice whether something is different from what they have previously experienced. {[}example of a study instead of phone screen{]}. There is also a minimum amount of stimulation required in order for someone to be aware that something is happening. If a significant amount of time is elapsed between two events, one may be less likely to predict that one event caused another. For example, if you eat spoiled food but do not get sick until three weeks later, you may be less likely to predict that the food caused the illness than if you had become sick immediately after consumption. {[}another example from a study{]} Further, noise interference also plays a role. This can be anything that distracts a participant while they are trying to focus on the contingency task, such as thoughts, sounds, or other objects in sight. These factors can influence, positively or negatively, one's memory of the contingency task.

\hypertarget{memory-accounts}{%
\subsubsection{Memory accounts}\label{memory-accounts}}

MINERVA II assumes that repeated exposure to the same information creates multiple copies rather than strengthening the same memory. This is called multiple-trace theory. This theory is assumed for the purposes of this study. Unlike with associative theory, multiple-trace theory does not assume that memories are stored as abstract knowledge with episodic and generic memories. Instead, it assumes that there is one memory system that derives specific information from a pool of traces. These traces each contain a specific experience. It is still a non-instance theory, {[}right?{]} as, similar to the idea put forth by associative theory, it involves previous experiences influencing one's reaction to stimuli. Multiple-trace theory accounts for the outcome density effect by considering differential forgetting {[}expand{]}. As more instances of a particular memory occur, (for example, hearing the same word) people tend to forget details about specific previous occurrences. Multiple-traces still exist, but are weakened over time {[}right?{]}.

\hypertarget{minerva-ii}{%
\subsection{MINERVA II}\label{minerva-ii}}

MINERVA II is a computational instance theory of human memory (Hintzman, 1984, 1986, 1988). It is conceptually similar to other global-similarity models of memory (Eich, 1982; Murdock, 1993). MINERVA II and related models have been applied to explain many kinds of cognitive phenomena and processes such as recognition memory (Arndt \& Hirshman, 1998), probability judgment and decision-making (Dougherty, Gettys, \& Ogden, 1999), artificial grammar learning (Jamieson \& Mewhort, 2009a), serial reaction time task performance (Jamieson \& Mewhort, 2009b), associative learning phenomena (Jamieson, Crump, \& Hannah, 2012), and computational accounts of semantic knowledge (Jamieson, Avery, Johns, \& Jones, 2018).

In MINERVA 2, memory is a matrix \(M\). Each row represents a memory trace, and the columns represent features of the trace.

How do we compute \(\triangle\)P? \(\triangle\)P is defined as the contingency between the cue-outcome pairs over trials. \enquote{C} and \enquote{O} denote cue and outcome, respectively. \enquote{\textasciitilde C} denotes that a cue does not occur, and \enquote{\textasciitilde O} denotes that an outcome does not occur (Crump et al., 2007).

\(\triangle\ P = P(O|C) - P(O| \tilde\ C) = \frac{A}{A+B} - \frac{C}{C+D}\)

How does encoding work? Individual events are represented as feature vectors \(E\), and new events are stored to the next row in the memory matrix \(M\). Individual features are stored with probability \(L\), representing quality of encoding.

How does retrieval work? A probe (feature vector for a current event in the environment) is submitted to memory, and causes traces to activate in proportion to their similarity to the probe. Similarity between each trace and the probe is computed with a cosine:

\(S_i = cos(\theta) = \frac{A \dot B}{||A|| ||B||}\)

\(S_i = \frac{\sum_{i=1}^n A_iB_i}{\sqrt{\sum_{i=1}^n A_i^2}\sqrt{\sum_{i=1}^n B_i^2}}\)

Where A is a probe and B is a memory trace in \(M\).

Activation as function of similarity raised to a power of three.

\(A_i = S_i^3\)

Each trace is then weighted by its activation (cubed similarity) to the probe, and summed to produce an echo.

\(C_j = \sum_{i=1}^m A_i \times M_{ij}\)

How is a contingency judgment computed? We take the raw values in the outcome portion of the echo as measures of expectation for the outcome given the cue.

\hypertarget{methods}{%
\section{Methods}\label{methods}}

We used RStudio to create a model of memory. Our model was presented with two types of streams, non-contingent and contingent. Non-contingent refers to trials where \(\triangle\)P is 0. This means there is no relationship between the cues and outcomes shown, regardless of outcome density. Cues do not predict outcomes, and outcomes do not predict cues. Contingent refers to trials where \(\triangle\)P is .467, where the presence of a cue does foreshadow the presence of an outcome. Each type of stream contained two conditions, low outcome density and high outcome density. Low outcome density refers to a trial in which fewer outcomes were presented than cues. Four types of trials were presented to the model. The model was presented with either, a cue and an outcome, a cue and no outcome, no cue and an outcome, or no cue and no outcome. After being shown these combinations many times, our model was asked to predict whether an outcome would occur given that cues were presented first with no outcomes.
As mentioned earlier, MINERVA II is a multiple trace model, and so it assumes that each experience leaves an individual memory trace (Hintzman, 1986). With repeated exposure to the same information, it creates multiple copies rather than strengthening the same memory. MINERVA II is mostly focused on long-term memory, however, there is assumed to be a temporary buffer (short-term memory) that relay information to long-term memory (Hintzman, 1988). The model was programmed in R and the code is presented in Appendix 1.
The original experiment performed by Crump et al. (2007) involved a blue square being presented as the cue and a red circle being presented as the outcome. Our model presents cues and outcomes to the model as sets of 0s and 1s. 0 being not present, 1 being present. If a cue was presented first (1), it may have either been followed by an outcome (1), or no outcome (0). If no cue was presented first (0), it was either followed by no outcome, or an outcome. In theory, the more cues and outcomes presented, the more accurate the model will be at predicting the presence or absence of each.

\hypertarget{simulation-1}{%
\section{Simulation 1}\label{simulation-1}}

\hypertarget{results}{%
\section{Results}\label{results}}

\begin{figure}
\centering
\includegraphics{imgs/crump_results.png}
\caption{\label{fig:unnamed-chunk-3}Original results reprinted from Crump et al. (2007)}
\end{figure}

The original results from Crum et al.~(2007) are shown in Figure 1. The figure shows that, for non-contingent conditions (\(\triangle\)P=0, diamond shape), contingency ratings were lower for both low and high outcome density conditions. Participants' contingency ratings were highest overall during contingent conditions (\(\triangle\)P=.467, diamond shape). However, regardless of stream condition, contingency ratings were always higher when outcome density was larger. This trend indicates that the \(\triangle\)P effect is present. As shown in the figure, some participants gave negative contingency ratings. This is of particular note, as each condition contained an outcome density greater than or equal to 0. This shows that the outcome density effect is present.

\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/unnamed-chunk-4-1.pdf}
\caption{\label{fig:unnamed-chunk-4}Mean Contingency Ratings Based on Outcome Density}
\end{figure}

Did our MINERVA model produce a similar \(\triangle\)P effect and outcome density effect to those found in the Crump et al. (2007) study? The results of the model simulations are shown in Figure 2. For both contingent (\(\triangle\)P=.467) and non-contingent (\(\triangle\)P=0) streams of data, contingency ratings (Outcome Activation Strength in Echo) were lower when less outcomes were presented (low outcome density, lower Probability of Outcome). Just like the human participants in the original study, our computer model also had higher contingency ratings when more outcomes were presented than cues (high outcome density, greater Probability of Outcome). In contingent conditions, contingency ratings were much higher overall than in non-contingent conditions. As intended, our results paralleled those of the original study.

\hypertarget{discussion}{%
\section{Discussion}\label{discussion}}

The purpose of this experiment was to create a simulated version of the study performed by Crump et al. (2007). In general, our model was able to replicate several attributes of the in-person study, such as the \(\triangle\)P conditions and the outcome densities associated with them. This suggests that contingency judgements can be explained in terms of memory processes.
By studying contingency judgements, we can gain a better understanding of factors that influence learning, memory, and eventually decision making. Our results indicate that there is a relationship between the number of times an outcome is shown, and one's prediction of whether or not an outcome will occur based on a cue. This general principle may have real-world implications, such as in regard to interpreting data. One may falsely attribute one variable to causing another based on often experiencing both variables together. This relates to the statistical principle \enquote{correlation does not imply causation}. {[}expand{]}
{[}Fundamental attribution error explanation and comparison?{]}

\hypertarget{limitations}{%
\subsection{Limitations}\label{limitations}}

Our model contains several key differences when compared with the original study done by Crump et al. (2007). One major difference between our model and the in-person study is that our simulation did not produce any negative ratings. Specifically, the outcome density effect was not present. Several factors may explain this result, such as the fact that no human participants were included in our study. In the low outcome density condition (\(\triangle\)P=0) of the original study, human beings gave negative ratings. This was likely due to the outcome density effect. This phenomenon was not present in our simulation data {[}was the effect present?{]}. Another factor that may explain this result is the possibility that we overlooked particular variables when creating our model. It could be the case that we neglected to implement code for some aspect of attention or memory.

\hypertarget{future-research}{%
\subsection{Future Research}\label{future-research}}

In order to create a model that produces results that are more to the original study, we {[}created (should I include this?){]} a negative contingency condition. In this condition, we set \(\triangle\)P equal to -.467, meaning that the presence of a cue would predict the absence of an outcome. In this condition, the model was more likely to give negative ratings of contingency.

\newpage

\hypertarget{references}{%
\section{References}\label{references}}

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

\hypertarget{refs}{}
\leavevmode\hypertarget{ref-arndtTrueFalseRecognition1998}{}%
Arndt, J., \& Hirshman, E. (1998). True and False Recognition in MINERVA2: Explanations from a Global Matching Perspective. \emph{Journal of Memory and Language}, \emph{39}(3), 371--391. \url{https://doi.org/10/bf5r6d}

\leavevmode\hypertarget{ref-crumpContingencyJudgementsFly2007}{}%
Crump, M. J. C., Hannah, S. D., Allan, L. G., \& Hord, L. K. (2007). Contingency judgements on the fly. \emph{The Quarterly Journal of Experimental Psychology}, \emph{60}(6), 753--761. \url{https://doi.org/10/b9jjc4}

\leavevmode\hypertarget{ref-doughertyMINERVADMMemoryProcesses1999}{}%
Dougherty, M. R., Gettys, C. F., \& Ogden, E. E. (1999). MINERVA-DM: A memory processes model for judgments of likelihood. \emph{Psychological Review}, \emph{106}(1), 180--209. \url{https://doi.org/10/ct5hdj}

\leavevmode\hypertarget{ref-eichCompositeHolographicAssociative1982}{}%
Eich, J. M. (1982). A composite holographic associative recall model. \emph{Psychological Review}, \emph{89}(6), 627--661. \url{https://doi.org/10/fkjzpx}

\leavevmode\hypertarget{ref-hintzmanMINERVASimulationModel1984}{}%
Hintzman, D. L. (1984). MINERVA 2: A simulation model of human memory. \emph{Behavior Research Methods, Instruments, \& Computers}, \emph{16}(2), 96--101. \url{https://doi.org/10/fx78p6}

\leavevmode\hypertarget{ref-hintzmanSchemaAbstractionMultipletrace1986}{}%
Hintzman, D. L. (1986). Schema abstraction in a multiple-trace memory model. \emph{Psychological Review}, \emph{93}(4), 411--428. \url{https://doi.org/10/bzdsr4}

\leavevmode\hypertarget{ref-hintzmanJudgmentsFrequencyRecognition1988}{}%
Hintzman, D. L. (1988). Judgments of frequency and recognition memory in a multiple-trace memory model. \emph{Psychological Review}, \emph{95}(4), 528--551. \url{https://doi.org/10/fnm39h}

\leavevmode\hypertarget{ref-jamiesonInstanceTheorySemantic2018}{}%
Jamieson, R. K., Avery, J. E., Johns, B. T., \& Jones, M. N. (2018). An instance theory of semantic memory. \emph{Computational Brain \& Behavior}, \emph{1}(2), 119--136. \url{https://doi.org/10/gf6cm7}

\leavevmode\hypertarget{ref-jamiesonInstanceTheoryAssociative2012}{}%
Jamieson, R. K., Crump, M. J. C., \& Hannah, S. D. (2012). An instance theory of associative learning. \emph{Learning \& Behavior}, \emph{40}(1), 61--82. \url{https://doi.org/10/dwkrm5}

\leavevmode\hypertarget{ref-jamiesonApplyingExemplarModel2009}{}%
Jamieson, R. K., \& Mewhort, D. J. (2009a). Applying an exemplar model to the artificial-grammar task: Inferring grammaticality from similarity. \emph{The Quarterly Journal of Experimental Psychology}, \emph{62}(3), 550--575. \url{https://doi.org/10/d8xpjj}

\leavevmode\hypertarget{ref-jamiesonApplyingExemplarModel2009a}{}%
Jamieson, R. K., \& Mewhort, D. J. (2009b). Applying an exemplar model to the serial reaction-time task: Anticipating from experience. \emph{The Quarterly Journal of Experimental Psychology}, \emph{62}(9), 1757--1783. \url{https://doi.org/10/cds843}

\leavevmode\hypertarget{ref-murdockTODAM2ModelStorage1993}{}%
Murdock, B. B. (1993). TODAM2: A model for the storage and retrieval of item, associative, and serial-order information. \emph{Psychological Review}, \emph{100}(2), 183--203. \url{https://doi.org/10/fwc536}

\endgroup


\end{document}
