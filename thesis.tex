% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  english,
  man,floatsintext]{apa6}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
  \usepackage{amssymb}
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Explaining contingency judgements with a computational model of instance-based memory},
  pdfauthor={Austin Kaplan1},
  pdflang={en-EN},
  pdfkeywords={memory, contingency judgments, MINERVA II, instance theory},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
% Manuscript styling
\usepackage{upgreek}
\captionsetup{font=singlespacing,justification=justified}

% Table formatting
\usepackage{longtable}
\usepackage{lscape}
% \usepackage[counterclockwise]{rotating}   % Landscape page setup for large tables
\usepackage{multirow}		% Table styling
\usepackage{tabularx}		% Control Column width
\usepackage[flushleft]{threeparttable}	% Allows for three part tables with a specified notes section
\usepackage{threeparttablex}            % Lets threeparttable work with longtable

% Create new environments so endfloat can handle them
% \newenvironment{ltable}
%   {\begin{landscape}\begin{center}\begin{threeparttable}}
%   {\end{threeparttable}\end{center}\end{landscape}}
\newenvironment{lltable}{\begin{landscape}\begin{center}\begin{ThreePartTable}}{\end{ThreePartTable}\end{center}\end{landscape}}

% Enables adjusting longtable caption width to table width
% Solution found at http://golatex.de/longtable-mit-caption-so-breit-wie-die-tabelle-t15767.html
\makeatletter
\newcommand\LastLTentrywidth{1em}
\newlength\longtablewidth
\setlength{\longtablewidth}{1in}
\newcommand{\getlongtablewidth}{\begingroup \ifcsname LT@\roman{LT@tables}\endcsname \global\longtablewidth=0pt \renewcommand{\LT@entry}[2]{\global\advance\longtablewidth by ##2\relax\gdef\LastLTentrywidth{##2}}\@nameuse{LT@\roman{LT@tables}} \fi \endgroup}

% \setlength{\parindent}{0.5in}
% \setlength{\parskip}{0pt plus 0pt minus 0pt}

% \usepackage{etoolbox}
\makeatletter
\patchcmd{\HyOrg@maketitle}
  {\section{\normalfont\normalsize\abstractname}}
  {\section*{\normalfont\normalsize\abstractname}}
  {}{\typeout{Failed to patch abstract.}}
\patchcmd{\HyOrg@maketitle}
  {\section{\protect\normalfont{\@title}}}
  {\section*{\protect\normalfont{\@title}}}
  {}{\typeout{Failed to patch title.}}
\makeatother
\shorttitle{Memory and contingency judgments}
\keywords{memory, contingency judgments, MINERVA II, instance theory\newline\indent Word count: 2180}
\usepackage{lineno}

\linenumbers
\usepackage{csquotes}
\ifxetex
  % Load polyglossia as late as possible: uses bidi with RTL langages (e.g. Hebrew, Arabic)
  \usepackage{polyglossia}
  \setmainlanguage[]{english}
\else
  \usepackage[shorthands=off,main=english]{babel}
\fi
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1 \everypar{\setlength{\hangindent}{\cslhangindent}}\ignorespaces\fi
  % set entry spacing
  \ifnum #2 > 0
  \setlength{\parskip}{#2\baselineskip}
  \fi
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\title{Explaining contingency judgements with a computational model of instance-based memory}
\author{Austin Kaplan\textsuperscript{1}}
\date{}


\authornote{

Brooklyn College of Psychology, submitted for PSYC 5001 (Dr.~Matthew Crump) as part of a two-semester honors thesis. This paper will be integrated into the final honors thesis to be submitted for PSYC 5002.

Correspondence concerning this article should be addressed to Austin Kaplan, 2900 Bedford Avenue. E-mail: \href{mailto:aus10kap@aol.com}{\nolinkurl{aus10kap@aol.com}}

}

\affiliation{\vspace{0.5cm}\textsuperscript{1} Brooklyn College}

\abstract{
The purposes of this experiment were to create a simulated version of the Crump, Hannah, Allan, and Hord (2007) study and additionally to experiment with new theoretical conditions within the simulation. Our model replicated several key findings, such as the effects of \(\triangle\)P and outcome density. We created a model using RStudio, based on MINERVA 2, which is a simulation model of episodic memory (Hintzman, 1986). MINERVA 2 assumes that each experience leaves an individual memory trace. Our model was presented with six different conditions. Three were high outcome density and three were low outcome density conditions. Low outcome density refers to a trial in which fewer outcomes were presented than cues. High outcome density refers to trials where more outcomes were presented than cues. Four types of trials can be presented to the model. The model can be presented with a cue and no outcome, no cue and no outcome, a cue and an outcome, or no cue and an outcome. Our model was shown all four combinations. It was then asked to predict, based on all of the combinations that it had been presented with, whether an outcome would occur given that cues were presented first with no outcomes. We hypothesized that Just like the human participants in the original study, our computer model also had higher contingency ratings when more outcomes were presented than cues (high outcome density). In contingent conditions (\(\triangle\)P=.467), contingency ratings were much higher overall than noncontingent conditions (\(\triangle\)P=0), which, as intended, paralleled the original results. However, it did so with regard to a higher expectation overall than that of the original study. We also presented the model with a negative contingency condition (\(\triangle\)P=-.467) that was not present in the original study. Our results show that, in theory, had this been the case in the original study, participants would have least expected the occurrence of an outcome under these conditions.
}



\begin{document}
\maketitle

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Imagine that you are driving down a highway going sixty miles per hour. All of the sudden traffic slows down and you see two police cars pass by. ``I guess there was an accident,'' you think to yourself as you anticipate a longer commute than expected. You later pass the cars involved, and also arrive twenty minutes late to work. Why did you predict that a car crash had occurred? Why did you predict that you would have a longer commute time? These types of questions are asked by researchers when studying contingency judgements. A contingency judgement can be defined as one's perception of whether a particular stimulus predicts a particular outcome. The purpose of studying human contingency judgements is to be able to gain a better understanding of the way that people learn about the causal relationships between events (Beckers, 2011).

In order to study this further, we created a model using RStudio. The model attempts to help us understand the way in which contingency judgements are made. Our model is based on MINERVA 2, which is a simulation model of episodic memory. Specifically, MINERVA 2 assumes that each experience leaves an individual memory trace (Hintzman, 1986). Our model focuses on evaluating the percentage of information remembered after cues and outcomes are first presented. The model is first presented a set amount of cues and outcomes, and its ``memory'' is then checked by ``asking'' the model to predict whether an outcome will occur given that a cue was presented or not.

Our experiment is based on a research study performed by Crump, Hannah, Allan, and Hord (2007). While this study involved presenting humans with a contingency task, our computer model attempts to replicate the findings of the study, and expand upon it. The findings of the original study explain that people are generally normative. In other words, people generally act in an expected way when making contingency judgements, and this is referred to as the \(\triangle\)P rule (Allan, 1993). For instance, if someone changes the brightness of their phone screen and it becomes brighter, a person will likely be able to tell that an increase occurred rather than a decrease, or no change. This would be expected, or normative, behavior. By the same token, human beings are not robots, and each person has their own biases. For instance, one may rate contingency as significantly higher or lower than actuality. These biases result in a departure from expectations during research. This phenomenon is explained by the outcome density effect. This states that when more outcomes occur, they lead participants to more strongly predict that there is a contingency occurring in order to create the outcomes, even if there is not necessarily a true contingency between events. For instance, if someone is shown a circle followed by a square 95 of the time, they are more likely to predict that the circle indicates that a square will be presented later, even if the order was randomly generated and no connection between the two cues was intended. What psychological mechanisms are involved in making contingency judgements? Several theories can be used to explain the way in which contingency judgements work. MINERVA 2 assumes that repeated exposure to the same information creates multiple copies rather than strengthening the same memory. This is called multiple-trace theory. While this theory is assumed for the purposes of this study, many other models attempt to explain how contingency judgments are formed. One of these is called rule-based theory. This theory looks at people or even animals as intuitive statisticians who extract contingency information by applying formulas (Allan, 1993). In other words, animals and humans act as ``calculators'' unwittingly. For instance, Another theory is associative theory, which looks at contingency learning as a result of Pavolvian associations formed between all previously presented events (Allan, 1993). This is based on the Rescorla-Wagner model of learning, which explains that learning diminishes as the conditioned stimulus becomes more familiar. This makes the case that contingencies are learned through the repeated presentation of stimuli. For instance, in Crump, Hannah, Allan, and Hord (2007), when a red circle is presented after a blue square, participants learn to associate the circle with the square and form a judgement that the circle is contingent upon the prior presentation of the square. Signal detection theory deals with measuring one's ability to differentiate between actual information and random patterns that distract from it. Based on this theory, contingency judgements are formed based on how well one is able to separate noise (random pairings) from actual contingencies. Several factors may influence whether or not one is able to make an accurate contingency judgement. First, there is a minimum amount of change necessary for one to tell whether something is different from before. For instance, if someone only changes the brightness on their phone by 1\% would one be able to notice? There is also a minimum amount of stimulation required in order for someone to be aware that something is happening. For instance, if a significant amount of time is elapsed between two events, one may be less likely to predict that one event caused the other to occur. For instance, if you eat spoiled food but do not get sick until three weeks later, you may be less likely to predict that the food caused the illness than if you got sick the next day. Further, noise interference also plays a role. This is anything that distracts the participant in some way while they are trying to focus on the contingency task. Other thoughts, sounds, or objects in sight can create noise in one's memory. These factors can take away from or add to a participant's memory of the task. Noise may reduce contingency judgement accuracy.

\hypertarget{minerva-ii}{%
\subsection{MINERVA II}\label{minerva-ii}}

MINERVA II is a computational instance theory of human memory (Hintzman, 1984, 1986, 1988). It is conceptually similar to other global-similarity models of memory Eich (1982). MINERVA II and related models have been applied to explain many kinds of cognitive phenomena and processes such as recognition memory (Arndt \& Hirshman, 1998), probability judgment and decision-making (Dougherty, Gettys, \& Ogden, 1999), artificial grammar learning (Jamieson \& Mewhort, 2009a), serial reaction time task performance (Jamieson \& Mewhort, 2009b), associative learning phenomena (Jamieson, Crump, \& Hannah, 2012), and computational accounts of semantic knowledge (Jamieson, Avery, Johns, \& Jones, 2018).

In MINERVA 2, memory is a matrix \(M\). Each row represents a memory trace, and the columns represent features of the trace.

How does encoding work? Individual events are represented as feature vectors \(E\), and new events are stored to the next row in the memory matrix \(M\). Individual features are stored with probability \(L\), representing quality of encoding.

How does retrieval work? A probe (feature vector for a current event in the environment) is submitted to memory, and causes traces to activate in proportion to their similarity to the probe. Similarity between each trace and the probe is computed with a cosine:

\(S_i = cos(\theta) = \frac{A \dot B}{||A|| ||B||}\)

\(S_i = \frac{\sum_{i=1}^n A_iB_i}{\sqrt{\sum_{i=1}^n A_i^2}\sqrt{\sum_{i=1}^n B_i^2}}\)

Where A is a probe and B is a memory trace in \(M\).

Activation as function of similarity raised to a power of three.

\(A_i = S_i^3\)

Each trace is then weighted by its activation (cubed similarity) to the probe, and summed to produce an echo.

\(C_j = \sum_{i=1}^m A_i \times M_{ij}\)

How is a contingency judgment computed? We take the raw values in the outcome portion of the echo as measures of expectation for the outcome given the cue.

\hypertarget{methods}{%
\section{Methods}\label{methods}}

We used RStudio to create a model of memory. Our model was presented with six different conditions. Three were high outcome density and three were low outcome density conditions. Low outcome density refers to a trial in which fewer outcomes were presented than cues. High outcome density refers to trials where more outcomes were presented than cues. Four types of trials can be presented to the model. The model can be presented with a cue and no outcome, no cue and no outcome, a cue and an outcome, or no cue and an outcome. Our model was shown all four combinations. It was then asked to predict, based on all of the combinations that it had been presented with, whether an outcome would occur given that cues were presented first with no outcomes.

The three types of streams presented were noncontingent, contingent, and negative contingent. Noncontingent refers to trials where cues and outcomes were presented randomly, with neither meant to predict the other. Contingent refers to when an outcome was predicted given a cue. Negative contingent refers to when an outcome was predicted despite no cue given.

MINERVA 2 is a multiple-trace model as it assumes that each experience leaves an individual memory trace (Hintzman,1986). In other words, repeated exposure to the same information creates multiple copies rather than strengthening the same memory. MINERVA 2 is mostly focused on long-term memory. However, there is assumed to be a temporary buffer (short-term memory) that relays information to long-term memory (Hintzman, 1988). The model was programmed in R and the code is presented in Appendix 1.

The original experiment by Crump et al.~involved a blue square being presented as the cue and a red circle being presented as the outcome. Our model presents cues and outcomes to the model as sets of 0s and 1s. 0 being not present, 1 being present. Specifically, in our simulation, the model was shown 0s and 1s as representations of cues and outcomes, respectively. If a cue was presented first, it may have either been followed by an outcome (1), or no outcome (0). If no cue was presented first (0), it was either followed by no outcome, or an outcome. In theory, the more cues and outcomes presented, the more accurate the model should be at predicting which number will be presented next.

\hypertarget{simulation-1}{%
\section{Simulation 1}\label{simulation-1}}

\hypertarget{results}{%
\section{Results}\label{results}}

\begin{figure}
\includegraphics[width=2.53in]{imgs/crump_results} \caption{Original results reprinted from Crump et al. (2007)}\label{fig:unnamed-chunk-2}
\end{figure}

The original results from Crump, Hannah, Allan, and Hord (2007) are shown in Figure 1. Describe the meaning of the figure\ldots Describe the main effect of contingency. Describe the main effect of outcome density.

\begin{figure}
\centering
\includegraphics{thesis_files/figure-latex/unnamed-chunk-3-1.pdf}
\caption{\label{fig:unnamed-chunk-3}Write a caption for figure 1}
\end{figure}

Did our MINERVA model produce a similar \(\triangle\)P effect and outcome density effect to those found in the Crump et al.~(2007) study? The results of the model simulations are shown in Figure 2. For both contingent and noncontingent streams of data, contingency ratings were lower when less outcomes were presented. Just like the human participants in the original study, our computer model also had higher contingency ratings when more outcomes were presented than cues (high outcome density). In contingent conditions (\(\triangle\)P=.467), contingency ratings were much higher overall than noncontingent conditions (\(\triangle\)P=0), which, as intended, paralleled the results of the original study.

\hypertarget{discussion}{%
\section{Discussion}\label{discussion}}

The purposes of this experiment were to create a simulated version of the Crump et al.~(2007) study. In general, our model was able to replicate several attributes of the in-person study, such as the \(\triangle\)P conditions and the outcome densities associated with them. This suggests that aspects of contingency judgments can be explained in terms of memory processes.

Our model contains several key differences when compared with the original study done by Crump et al.~(2007). \textbf{Discuss that our model did not produce any negative ratings. Notice that in the delta P = 0, low outcome density condition people gave negative ratings. Why didn't our model produce a negative rating here? discuss next steps\ldots first check if MINERVA 2 can become sensitive to negative contingencies\ldots then change how we measure the model in order to calculate a delta p value that could be negative.}

By studying contingency judgements, we can gain a better understanding of factors that influence learning, memory, and eventually decision making. Our results indicate that there is a relationship between the number of times a result is shown, and one's prediction of whether or not they will get that an outcome will occur based on a certain cue. This general principle may have implications in the world of mental health, such as with disorders such as anxiety and depression. For instance, it could be the case that one develops depressive symptoms due in part to what they expect to happen (outcomes), based on previous experiences (cues). Of course, it would require a substantial amount of further research to properly examine how previous experiences shape mental disorders.

\newpage

\hypertarget{references}{%
\section{References}\label{references}}

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\hypertarget{ref-allanHumanContingencyJudgments1993}{}%
Allan, L. G. (1993). Human contingency judgments: {Rule} based or associative? \emph{Psychological Bulletin}, \emph{114}(3), 435--448. \url{https://doi.org/dw9tzr}

\leavevmode\hypertarget{ref-arndtTrueFalseRecognition1998}{}%
Arndt, J., \& Hirshman, E. (1998). True and {False Recognition} in {MINERVA2}: {Explanations} from a {Global Matching Perspective}. \emph{Journal of Memory and Language}, \emph{39}(3), 371--391. \url{https://doi.org/bf5r6d}

\leavevmode\hypertarget{ref-crumpContingencyJudgementsFly2007}{}%
Crump, M. J. C., Hannah, S. D., Allan, L. G., \& Hord, L. K. (2007). Contingency judgements on the fly. \emph{The Quarterly Journal of Experimental Psychology}, \emph{60}(6), 753--761. \url{https://doi.org/b9jjc4}

\leavevmode\hypertarget{ref-doughertyMINERVADMMemoryProcesses1999}{}%
Dougherty, M. R., Gettys, C. F., \& Ogden, E. E. (1999). {MINERVA}-{DM}: {A} memory processes model for judgments of likelihood. \emph{Psychological Review}, \emph{106}(1), 180--209. \url{https://doi.org/ct5hdj}

\leavevmode\hypertarget{ref-eichCompositeHolographicAssociative1982}{}%
Eich, J. M. (1982). A composite holographic associative recall model. \emph{Psychological Review}, \emph{89}(6), 627--661. \url{https://doi.org/fkjzpx}

\leavevmode\hypertarget{ref-hintzmanMINERVASimulationModel1984}{}%
Hintzman, D. L. (1984). {MINERVA} 2: {A} simulation model of human memory. \emph{Behavior Research Methods, Instruments, \& Computers}, \emph{16}(2), 96--101. \url{https://doi.org/fx78p6}

\leavevmode\hypertarget{ref-hintzmanSchemaAbstractionMultipletrace1986}{}%
Hintzman, D. L. (1986). Schema abstraction in a multiple-trace memory model. \emph{Psychological Review}, \emph{93}(4), 411--428. \url{https://doi.org/bzdsr4}

\leavevmode\hypertarget{ref-hintzmanJudgmentsFrequencyRecognition1988}{}%
Hintzman, D. L. (1988). Judgments of frequency and recognition memory in a multiple-trace memory model. \emph{Psychological Review}, \emph{95}(4), 528--551. \url{https://doi.org/fnm39h}

\leavevmode\hypertarget{ref-jamiesonInstanceTheorySemantic2018}{}%
Jamieson, R. K., Avery, J. E., Johns, B. T., \& Jones, M. N. (2018). An instance theory of semantic memory. \emph{Computational Brain \& Behavior}, \emph{1}(2), 119--136. \url{https://doi.org/gf6cm7}

\leavevmode\hypertarget{ref-jamiesonInstanceTheoryAssociative2012}{}%
Jamieson, R. K., Crump, M. J. C., \& Hannah, S. D. (2012). An instance theory of associative learning. \emph{Learning \& Behavior}, \emph{40}(1), 61--82. \url{https://doi.org/dwkrm5}

\leavevmode\hypertarget{ref-jamiesonApplyingExemplarModel2009}{}%
Jamieson, R. K., \& Mewhort, D. J. (2009a). Applying an exemplar model to the artificial-grammar task: {Inferring} grammaticality from similarity. \emph{The Quarterly Journal of Experimental Psychology}, \emph{62}(3), 550--575. \url{https://doi.org/d8xpjj}

\leavevmode\hypertarget{ref-jamiesonApplyingExemplarModel2009a}{}%
Jamieson, R. K., \& Mewhort, D. J. (2009b). Applying an exemplar model to the serial reaction-time task: {Anticipating} from experience. \emph{The Quarterly Journal of Experimental Psychology}, \emph{62}(9), 1757--1783. \url{https://doi.org/cds843}

\leavevmode\hypertarget{ref-murdockTODAM2ModelStorage1993}{}%
Murdock, B. B. (1993). {TODAM2}: A model for the storage and retrieval of item, associative, and serial-order information. \emph{Psychological Review}, \emph{100}(2), 183--203. \url{https://doi.org/fwc536}

\end{CSLReferences}

\endgroup


\end{document}
